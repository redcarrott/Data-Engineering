{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa59bea0",
   "metadata": {},
   "source": [
    "# Tracking User Behavior on \"Best Chef\" (mobile game) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc1fe4",
   "metadata": {},
   "source": [
    "### Problem Statement \n",
    "\"Best Chef\" is an RPG-style mobile game. Users are chefs who can join restuarants (ie. like teams/clubs) and enter cooking competitions. The game is free on the app stores, and the Game Company generates revenue from in-app purchases (ie. buying ingredients, extra features, etc.) Therefore, to maximize in-app purchases, it is critical to keep users engaged in the game. Certain actions may contribute more than others in increasing user engagement and willingness to purchase extra features. Therefore, it is crucial that the company tracks all user actions during the game, including metadata associated with each event (ie. timestamp, ingredient type, restaurant name). With this data, the company's data science team will be able to provide insights to the game development and design teams in order to maximize user engagement on \"Best Chef\" and revenue for Game Company. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2cb1d",
   "metadata": {},
   "source": [
    "### Objective\n",
    "Track user behavior in stream mode and prepare the infrastructure to land data in appropriate form and structure to be queried by data scientists. This process includes the following:\n",
    "- Instrument the API server to log events into Kafka\n",
    "- Assemble data pipeline: use Spark streaming to filter and select event types from Kafka, land into HDFS/Parquet to make data available for analysis using Presto\n",
    "- Use Apache Bench to generate test data for pipeline\n",
    "- Produce analytics report for development and design teams with analysis of events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9831472",
   "metadata": {},
   "source": [
    "### Tools\n",
    "This project was executed on Google Cloud Platform (GCP) with the following tools:\n",
    "- Docker/docker-compose (to set-up the cluster of containers)\n",
    "- Flask (to instrument our web server API)\n",
    "- Kafka (to publish and consume messages)\n",
    "- Zookeeper (broker)\n",
    "- Spark/pyspark (to extract, filter, flatten and load the messages into HDFS)\n",
    "- Cloudera/HDFS (to store final data in Parquet format)\n",
    "- Hive metastore (schema registry)\n",
    "- Presto (to query the data from HDFS)\n",
    "- Linux Bash (to run commands and scripts through CLI)\n",
    "- Apache Bench (to simulate user interactions with the app)\n",
    "- Python 3 json package (to wrap and unwrap JSON data models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d486a3",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "1. User interacts with mobile app game\n",
    "2. Mobile app makes API calls to web services\n",
    "3. API server handles requests: [OUT OF SCOPE FOR THIS PROJECT]\n",
    "    - ie. process game actions, in-game purchases, etc.\n",
    "    - logs events (user actions) to kafka\n",
    "4. Spark pull sevents form kafka, filters event by type, applies data schemas, writes to HDFS in Parquet format\n",
    "5. Hive reads Parquet files and creates tables for queries\n",
    "6. Presto used to query tables for data analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b9824",
   "metadata": {},
   "source": [
    "### Tracked events\n",
    "In this project, 3 types of evets are tracked:\n",
    "1. Purchase an ingredient\n",
    "2. Join a restaurant\n",
    "3. Enter a contest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46979d66",
   "metadata": {},
   "source": [
    "### Bash commands used to create pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c26d9",
   "metadata": {},
   "source": [
    "**Spin up cluster**\n",
    "```bash\n",
    "docker-compose up -d\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555dd9e6",
   "metadata": {},
   "source": [
    "**Perform checks**\n",
    "```bash\n",
    "docker-compose ps\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec244a",
   "metadata": {},
   "source": [
    "**Create event topics**\n",
    "```bash\n",
    "docker-compose exec kafka kafka-topics --create --topic events --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ec431",
   "metadata": {},
   "source": [
    "**Run FLask_App**\n",
    "```bash\n",
    "docker-compose exec mids env FLASK_APP=/w205/project-3-redcarrott/game_api.py flask run --host 0.0.0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0448a781",
   "metadata": {},
   "source": [
    "**Generate random events through Apache Bench**\n",
    "```bash\n",
    "chmod +x ab_events_publisher.sh ./ab_events_publisher.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7112c25b",
   "metadata": {},
   "source": [
    "**Read from kafka**\n",
    "```bash\n",
    "docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b0744",
   "metadata": {},
   "source": [
    "**Spark stream: run it**\n",
    "```bash\n",
    "docker-compose exec spark spark-submit /w205/project-3-redcarrott/filtered_writes_stream.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c0d70",
   "metadata": {},
   "source": [
    "**Spark stream: feed it**\n",
    "```bash\n",
    "while true; do docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/purchase_an_ingredient; sleep 10; done\n",
    "\n",
    "while true; do docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/join_a_restaurant; sleep 10; done\n",
    "\n",
    "while true; do docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/enter_a_contest; sleep 10; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c382b",
   "metadata": {},
   "source": [
    "**Check out results in Hadoop**\n",
    "```bash\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/purchase_ingredient\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/join_restaurant\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/enter_contest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32eb51",
   "metadata": {},
   "source": [
    "*2 ways to create tables in Hive* \\\n",
    "**1) Create tables in Hive, one per event type**\n",
    "```bash\n",
    "docker-compose exec cloudera hive -f /w205/project-3-redcarrott/create_tables.hql\n",
    "```\n",
    "**2) Register tables with hive**\n",
    "```bash\n",
    "docker-compose exec spark spark-submit /w205/project-3-redcarrott/stream_and_hive.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1807aa",
   "metadata": {},
   "source": [
    "**Initiate Presto** \\\n",
    "*run in main prompt*\n",
    "```bash\n",
    "docker-compose exec presto presto --server presto:8080 --catalog hive --schema default;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45349424",
   "metadata": {},
   "source": [
    "**Check tables**\n",
    "```bash\n",
    "show tables; DESCRIBE hive.default.purchase_ingredient; DESCRIBE hive.default.join_restaurant; DESCRIBE hive.default.enter_contest;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c0043",
   "metadata": {},
   "source": [
    "**Run queries**\n",
    "\n",
    "*Which proportion of contests do users win?*\n",
    "```bash\n",
    "select outcome, count(*) as count from enter_contest where outcome is not null group by outcome;\n",
    "```\n",
    "|outcome | count |\n",
    "|--------|-------|\n",
    "|lost | 7 |\n",
    "|won | 3|\n",
    "\n",
    "*Which contests do users more frequently enter?*\n",
    "```bash\n",
    "select contest, count(*) as count from enter_contest where enemy is not null group by contest order by count desc;\n",
    "```\n",
    "|contest | count |\n",
    "|--------|-------|\n",
    "|Le Best Chef | 4 |\n",
    "|Taste of Home | 3|\n",
    "|Feast and Field | 3 |\n",
    "|Call Me Betty Crocker | 2 |\n",
    "|Bake Off | 1 |\n",
    "|(3 rows) |  |\n",
    "\n",
    "*Which ingredient is most purchased by users?*\n",
    "```bash\n",
    "select ingredient_type, count(*) as count from purchase_ingredient where ingredient_type is not null group by ingredientweapon_type order by count desc;\n",
    "```\n",
    "|ingredient_type | count |\n",
    "|--------|-------|\n",
    "|egg | 10 |\n",
    "|beef | 5 |\n",
    "|salt | 3 |\n",
    "|butter | 3 |\n",
    "|(6 rows) | |\n",
    "\n",
    "*Which restaurant is preferred by comcast users?*\n",
    "```bash\n",
    "select restaurant_name, count(*) as count from join_restaurant where restaurant_name is not null and host like '%.comcast.com' group by restaurant_name order by count desc;\n",
    "```\n",
    "|restaurant_name | count |\n",
    "|--------|-------|\n",
    "|Promiscuous Fork | 3 |\n",
    "|The Angry Avocado | 1 |\n",
    "|Call Your Mother | 1 |\n",
    "|(4 rows) | |"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
